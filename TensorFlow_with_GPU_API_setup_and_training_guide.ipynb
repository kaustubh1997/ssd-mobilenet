{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU API setup and training guide",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "BlmQIFSLZDdc"
      },
      "cell_type": "markdown",
      "source": [
        "# Confirm TensorFlow can see the GPU\n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3IEVK-KFxi5Z",
        "outputId": "0940e8b1-5283-4b2d-e3e6-8853f3deb804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QXRh0DPiZRyG"
      },
      "cell_type": "markdown",
      "source": [
        "# Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t9ALbbpmY9rm",
        "outputId": "471c3b5a-d409-4850-8600-ef8b40f558c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "10.13828525999999\n",
            "GPU (s):\n",
            "0.19059632200000465\n",
            "GPU speedup over CPU: 53x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Omjg4VR354V3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**INTIAL WORKSPACE SETUP:**\n",
        "\n",
        "\n",
        "\n",
        "**1. FIRST GO TO EDIT >> NOTEBOOK SETTINGS >> SELECT HARDWARE ACCELERATOR AS GPU >> SAVE **\n",
        "\n",
        "\n",
        "**2. THEN PRESS \"CONNECT\" ON RIGHT TOP TOOLBAR TO CONNECT TO SESSION. THIS SESSION WILL LAST 12 HOURS. JUST TO BE ON THE SAFE SIDE, DONT DICONNECT COMPUTER FROM NETWORK OR CLOSE THE BROWSER**\n",
        "\n",
        "**3. AFTER CONNECTING, SELECT FILES TAB FROM LEFT PANEL TO SEE YOUR FILE SYSTEM**"
      ]
    },
    {
      "metadata": {
        "id": "Nme5t8vj7E9w",
        "colab_type": "code",
        "outputId": "a73c6ee7-5eb8-4551-d4fd-0417a8b7ba07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kaustubh1997/ssd-mobilenet.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ssd-mobilenet'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 55 (delta 13), reused 49 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (55/55), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oD09P1rQ7FGN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython\n",
        "!pip install jupyter\n",
        "!pip install matplotlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ciu-iGKC7FOU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_P59qJpZ7FV2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "!cd cocoapi/PythonAPI; make; cp -r pycocotools /content/models/research/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "863A4_PQ7Fdo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/models/research"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LkZvso9z7FlQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cSrBrAe17Fsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WR4b-6TI8hza",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install 'prompt-toolkit==1.0.15'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_jgkPOlj7Fz2",
        "colab_type": "code",
        "outputId": "c470a71c-4be9-42bc-ca66-41cb75858a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "......................\n",
            "----------------------------------------------------------------------\n",
            "Ran 22 tests in 0.120s\n",
            "\n",
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Gd0O1q17xtQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*The above line should display \"OK\". This indicates that your TensorFlow API setup is successful*"
      ]
    },
    {
      "metadata": {
        "id": "QRnG78_Y8sDN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Now copying our dataset tfrecords and config files to object_detection folder**"
      ]
    },
    {
      "metadata": {
        "id": "ihTFpyyy7F7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zZBX-EdK7GFG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cp -r ssd-mobilenet/ssd_mobilenet_v1_coco_2018_01_28/ models/research/object_detection/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LyX4pqAR9GXL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cp -r ssd-mobilenet/training/ models/research/object_detection/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZT2wc6YZ9btO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Note: for the next step, replace \"data_v3\" with latest data _v folder*"
      ]
    },
    {
      "metadata": {
        "id": "C2g8NyDC9Ghw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cp -r ssd-mobilenet/data_v3/data/ models/research/object_detection/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "asJCfSNb91xX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You can now navigate to models/research/object_detection/ from the Files Tab to the left to see that the folders have been copied into that directory*"
      ]
    },
    {
      "metadata": {
        "id": "fe5A6EJ79GoP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd models/research/object_detection/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jv1gcn36-Vmn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Now we will run model_main.py for training the model on our dataset:**\n",
        "\n",
        "---\n",
        "\n",
        "**In models/research/object_detection/training (in Files Tab), you can see event logs and model meta files being created and added as the process goes on. The training takes ~20 - 30 minutes**"
      ]
    },
    {
      "metadata": {
        "id": "_h54Meoj_NYW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*The code will run for 5000 steps. If required to run for more/less steps, change the arguments passed accordingly*"
      ]
    },
    {
      "metadata": {
        "id": "Nxv6sFxh9Gtv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 model_main.py --pipeline_config_path=training/ssd_mobilenet_v1_pets.config --model_dir=training --num_train_steps=5000 --sample_1_of_n_eval_examples=1 --alsologtostderr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GuU75v2O_X-g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**After training is completed, you may choose to zip the entire training directory and send it to your google drive, from where you can reliably download it and extract it to the same location (models/research/object_detection/training) on your computer**\n",
        "\n",
        "---\n",
        "\n",
        "*After extracting, you will have to run export_inference_graph.py on the checkpoint you want to convert to the inference graph. There are usually 2-3 checkpoints saved at various intervals from 1000-5000 training steps*"
      ]
    },
    {
      "metadata": {
        "id": "DX1FlNcv9G44",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!zip -r training.zip training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "noZbjKY3Azn7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nnEykWoKAzvy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "   file_metadata = {'name': name,'mimeType': 'application/octet-stream'}\n",
        "\n",
        "   media = MediaFileUpload(path, mimetype='application/octet-stream',resumable=True)\n",
        "\n",
        "   created = drive_service.files().create(body=file_metadata,media_body=media,fields='id').execute()\n",
        "\n",
        "   print('File ID: {}'.format(created.get('id')))\n",
        "\n",
        "   return created"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BgOr-u1kAz2H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_file_to_drive('training_v0.zip', 'training.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VqM5vW0cBvxr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Go to Drive, download your .zip from there**\n",
        "\n",
        "---\n",
        "\n",
        "After unpacking into required directory, you can run Tensorboard in your terminal at models/research/object_detection/ to see the results of your training"
      ]
    },
    {
      "metadata": {
        "id": "NJMvXtuoDLf2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tensorboard --logdir='training'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o46LHbGaDNlm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Open tensorboard on your web browser by going to http://localhost:6006/*\n",
        "\n",
        "---\n",
        "\n",
        "*Additionally, after unpacking into required directory, run the following command on you computer to get inference graph there. Running it here will create a inference graph there*\n",
        "\n",
        "*Note: change '\"78\" in the command line argument with the number of the checkpoint file which you want.*"
      ]
    },
    {
      "metadata": {
        "id": "0xdaPUf-BueQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 export_inference_graph.py --input_type image_tensor --pipeline_config_path training/ssd_mobilenet_v1_pets.config --trained_checkpoint_prefix training/model.ckpt-78 output_directory square_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GYGY9Wk8CfeS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**GREAT! Now you have a frozen inference graph for you checkpoint in a folder called square_out. You can load this in the ** *object_detection_tutorial.ipynb* **notebook, and test out images on the model (Do this on your PC)**"
      ]
    },
    {
      "metadata": {
        "id": "FgjJeYu2Bulw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}